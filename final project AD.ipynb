{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0c3042e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Cost of Minimum Spanning Tree: -5174\n",
      "Execution Time: 0.27806878089904785 seconds\n"
     ]
    }
   ],
   "source": [
    "#firt part of the project \n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import time\n",
    "\n",
    "# Step 1: Read the CSV file\n",
    "file = pd.read_csv('soc-sign-bitcoinotc.csv') \n",
    "\n",
    "# Step 2: Extract columns as source, target, and weight\n",
    "source = file.iloc[:, 0].tolist() # Extract first column data as source\n",
    "target = file.iloc[:, 1].tolist() # Extract second column data as target\n",
    "weights = file.iloc[:, 2].tolist() # Extract third column data as weights\n",
    "\n",
    "# Step 3: Create a graph\n",
    "G = nx.Graph()\n",
    "for i in range(len(source)):\n",
    "    G.add_edge(source[i], target[i], weight=weights[i])\n",
    "\n",
    "# Step 4: Compute Minimum Spanning Tree\n",
    "start_time = time.time()\n",
    "mst = nx.minimum_spanning_tree(G)\n",
    "total_cost = sum([edge[2]['weight'] for edge in mst.edges(data=True)])\n",
    "execution_time = time.time() - start_time\n",
    "print(f\"Total Cost of Minimum Spanning Tree: {total_cost}\")\n",
    "print(f\"Execution Time: {execution_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0b193082",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0: Cost = 295\n",
      "Cluster 1: Cost = 1215\n",
      "Cluster 2: Cost = -573\n",
      "Cluster 3: Cost = 6\n",
      "Cluster 4: Cost = 429\n",
      "Cluster 5: Cost = 3232\n",
      "Cluster 6: Cost = 354\n",
      "Cluster 7: Cost = 350\n",
      "Cluster 8: Cost = 915\n",
      "Cluster 9: Cost = 695\n",
      "Cluster 10: Cost = 277\n",
      "Cluster 11: Cost = 236\n",
      "Cluster 12: Cost = 1445\n",
      "Cluster 13: Cost = 498\n",
      "Cluster 14: Cost = 351\n",
      "Cluster 15: Cost = 45\n",
      "Cluster 16: Cost = 55\n",
      "Cluster 17: Cost = 71\n",
      "Cluster 18: Cost = 175\n",
      "Cluster 19: Cost = 753\n",
      "Cluster 20: Cost = -426\n",
      "Cluster 21: Cost = -109\n",
      "Cluster 22: Cost = 108\n",
      "Cluster 23: Cost = 843\n",
      "Cluster 24: Cost = 209\n",
      "Cluster 25: Cost = 1327\n",
      "Cluster 26: Cost = 140\n",
      "Cluster 27: Cost = -2435\n",
      "Cluster 28: Cost = 160\n",
      "Cluster 29: Cost = 576\n",
      "Cluster 30: Cost = 175\n",
      "Cluster 31: Cost = 437\n",
      "Cluster 32: Cost = 218\n",
      "Cluster 33: Cost = 226\n",
      "Cluster 34: Cost = -96\n",
      "Cluster 35: Cost = 414\n",
      "Cluster 36: Cost = -949\n",
      "Cluster 37: Cost = 113\n",
      "Cluster 38: Cost = 104\n",
      "Cluster 39: Cost = 709\n",
      "Cluster 40: Cost = 630\n",
      "Cluster 41: Cost = 703\n",
      "Cluster 42: Cost = 187\n",
      "Cluster 43: Cost = 382\n",
      "Cluster 44: Cost = 1031\n",
      "Cluster 45: Cost = 149\n",
      "Cluster 46: Cost = 65\n",
      "Cluster 47: Cost = 249\n",
      "Cluster 48: Cost = 1280\n",
      "Cluster 49: Cost = 300\n",
      "Cluster 50: Cost = 671\n",
      "Cluster 51: Cost = -32\n",
      "Cluster 52: Cost = 805\n",
      "Cluster 53: Cost = 176\n",
      "Cluster 54: Cost = 31\n",
      "Cluster 55: Cost = 387\n",
      "Cluster 56: Cost = 822\n",
      "Cluster 57: Cost = 110\n",
      "Cluster 58: Cost = 874\n",
      "Cluster 59: Cost = -191\n",
      "Cluster 60: Cost = 266\n",
      "Cluster 61: Cost = 338\n",
      "Cluster 62: Cost = 341\n",
      "Cluster 63: Cost = 568\n",
      "Cluster 64: Cost = 677\n",
      "Cluster 65: Cost = 115\n",
      "Cluster 66: Cost = 611\n",
      "Cluster 67: Cost = 418\n",
      "Cluster 68: Cost = 401\n",
      "Cluster 69: Cost = 426\n",
      "Cluster 70: Cost = -234\n",
      "Cluster 71: Cost = 652\n",
      "Cluster 72: Cost = 559\n",
      "Cluster 73: Cost = 892\n",
      "Cluster 74: Cost = -126\n",
      "Cluster 75: Cost = -224\n",
      "Cluster 76: Cost = 612\n",
      "Cluster 77: Cost = 178\n",
      "Cluster 78: Cost = 206\n",
      "Cluster 79: Cost = 171\n",
      "Cluster 80: Cost = 1271\n",
      "Cluster 81: Cost = 387\n",
      "Cluster 82: Cost = -90\n",
      "Cluster 83: Cost = -66\n",
      "Cluster 84: Cost = 498\n",
      "Cluster 85: Cost = 378\n",
      "Cluster 86: Cost = 166\n",
      "Cluster 87: Cost = 612\n",
      "Cluster 88: Cost = 644\n",
      "Cluster 89: Cost = 239\n",
      "Cluster 90: Cost = -542\n",
      "Cluster 91: Cost = 683\n",
      "Cluster 92: Cost = -818\n",
      "Cluster 93: Cost = 1402\n",
      "Cluster 94: Cost = 33\n",
      "Cluster 95: Cost = 1444\n",
      "Cluster 96: Cost = 450\n",
      "Cluster 97: Cost = 419\n",
      "Cluster 98: Cost = 405\n",
      "Cluster 99: Cost = 457\n",
      "Final MST cost: 36016\n",
      "Complete execution time: 0.9785 seconds\n"
     ]
    }
   ],
   "source": [
    "#second part of project\n",
    "import csv\n",
    "import timeit\n",
    "import threading\n",
    "import networkx as nx\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Read the CSV file\n",
    "csv_file_path = 'soc-sign-bitcoinotc.csv'\n",
    "source_col = []\n",
    "target_col = []\n",
    "rating_col = []\n",
    "\n",
    "with open(csv_file_path, mode='r') as file:\n",
    "    csv_reader = csv.reader(file)\n",
    "    next(csv_reader)  # Skip the header row\n",
    "    for row in csv_reader:\n",
    "        source_col.append(row[0])\n",
    "        target_col.append(row[1])\n",
    "        rating_col.append(int(row[2]))\n",
    "\n",
    "# Create a feature matrix (combine source and target columns)\n",
    "feature_matrix = [[s, t] for s, t in zip(source_col, target_col)]\n",
    "\n",
    "# Perform K-means clustering\n",
    "n_clusters = 100\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
    "cluster_labels = kmeans.fit_predict(feature_matrix)\n",
    "\n",
    "# Assign cluster labels to each data point\n",
    "for i, label in enumerate(cluster_labels):\n",
    "    source_col[i] = f\"{source_col[i]}_cluster{label}\"\n",
    "    target_col[i] = f\"{target_col[i]}_cluster{label}\"\n",
    "\n",
    "# Compute MST for each cluster\n",
    "def compute_mst(cluster_source, cluster_target, cluster_rating):\n",
    "    G = nx.Graph()\n",
    "    for s, t, w in zip(cluster_source, cluster_target, cluster_rating):\n",
    "        G.add_edge(s, t, weight=w)\n",
    "\n",
    "    mst = nx.minimum_spanning_tree(G)\n",
    "    return mst\n",
    "\n",
    "# Create threads for parallel processing\n",
    "threads = []\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "for i in range(n_clusters):\n",
    "    thread = threading.Thread(target=compute_mst, args=(source_col[i::n_clusters], target_col[i::n_clusters], rating_col[i::n_clusters]))\n",
    "    threads.append(thread)\n",
    "    thread.start()\n",
    "\n",
    "# Wait for all threads to finish\n",
    "for thread in threads:\n",
    "    thread.join()\n",
    "\n",
    "end_time = timeit.default_timer()\n",
    "execution_time = end_time - start_time\n",
    "\n",
    "# Calculate cost for each cluster\n",
    "cluster_costs = {}\n",
    "for i in range(n_clusters):\n",
    "    cluster_ratings = [r for r, label in zip(rating_col, cluster_labels) if label == i]\n",
    "    cluster_costs[f\"Cluster {i}\"] = sum(cluster_ratings)\n",
    "\n",
    "# Print cluster costs\n",
    "for cluster, cost in cluster_costs.items():\n",
    "    print(f\"{cluster}: Cost = {cost}\")\n",
    "#-------------Third part of project--------------\n",
    "# Create a function to merge two MSTs based on their lowest weighted edge\n",
    "def merge_msts(msts):\n",
    "    final_mst = nx.Graph()\n",
    "    for mst in msts:\n",
    "        for edge in mst.edges(data=True):\n",
    "            source, target, weight = edge\n",
    "            if final_mst.has_edge(source, target):\n",
    "                if weight['weight'] < final_mst[source][target]['weight']:\n",
    "                    final_mst[source][target]['weight'] = weight['weight']\n",
    "            else:\n",
    "                final_mst.add_edge(source, target, weight=weight['weight'])\n",
    "    return final_mst\n",
    "# Merge the resulting MST trees together\n",
    "mst_trees = []\n",
    "for i in range(n_clusters):\n",
    "    mst = compute_mst([source_col[j] for j in range(i, len(source_col), n_clusters)],\n",
    "                      [target_col[j] for j in range(i, len(target_col), n_clusters)],\n",
    "                      [rating_col[j] for j in range(i, len(rating_col), n_clusters)])\n",
    "    mst_trees.append(mst)\n",
    "\n",
    "final_mst = merge_msts(mst_trees)\n",
    "\n",
    "\n",
    "# Calculate cost of the final MST\n",
    "final_cost = sum(rating_col)\n",
    "print(f\"Final MST cost: {final_cost}\")\n",
    "\n",
    "# Print complete execution time\n",
    "print(f\"Complete execution time: {execution_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649c4665",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"comparison of total cost of MST and thier execution time between part 1 and part 2:\"\n",
    "#the total cost of the first part of project is less than the second part , because its final MST cost is calcalate based on the\n",
    "#individual weights from the CSV file \n",
    "#in the second part of the project , the total cost of the MST is calculated based on all the edge weights form the dataset\n",
    "#the execution time of the first part of the project is less than the second part, because When the MST algorithm is applied to \n",
    "#one individual graph, all the edges and vertices are considered together without any constraints or boundaries. This means that \n",
    "#the algorithm can find the minimum spanning tree by exploring all possible edges and vertices without any limitations.\n",
    "#On the other hand, when the graph is divided into different clusters, the algorithm needs to consider constraints and boundaries\n",
    "#between the clusters. This adds complexity to the algorithm as it needs to determine how to connect the different clusters in \n",
    "#a way that minimizes the overall cost while respecting the cluster boundaries.\n",
    "#As a result, the time execution of the MST algorithm may be longer when the graph is divided into different clusters compared\n",
    "#to when it is one individual graph because of the increased complexity and constraints involved in finding the MST.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
